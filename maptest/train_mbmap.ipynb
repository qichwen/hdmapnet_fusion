{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--logdir LOGDIR] [--dataroot DATAROOT]\n",
      "                             [--version {v1.0-trainval,v1.0-mini}]\n",
      "                             [--model MODEL] [--nepochs NEPOCHS]\n",
      "                             [--max_grad_norm MAX_GRAD_NORM]\n",
      "                             [--pos_weight POS_WEIGHT] [--bsz BSZ]\n",
      "                             [--nworkers NWORKERS] [--lr LR]\n",
      "                             [--weight_decay WEIGHT_DECAY] [--finetune]\n",
      "                             [--modelf MODELF] [--thickness THICKNESS]\n",
      "                             [--image_size IMAGE_SIZE IMAGE_SIZE]\n",
      "                             [--xbound XBOUND XBOUND XBOUND]\n",
      "                             [--ybound YBOUND YBOUND YBOUND]\n",
      "                             [--zbound ZBOUND ZBOUND ZBOUND]\n",
      "                             [--dbound DBOUND DBOUND DBOUND] [--instance_seg]\n",
      "                             [--embedding_dim EMBEDDING_DIM]\n",
      "                             [--delta_v DELTA_V] [--delta_d DELTA_D]\n",
      "                             [--direction_pred] [--angle_class ANGLE_CLASS]\n",
      "                             [--scale_seg SCALE_SEG] [--scale_var SCALE_VAR]\n",
      "                             [--scale_dist SCALE_DIST]\n",
      "                             [--scale_direction SCALE_DIRECTION]\n",
      "ipykernel_launcher.py: error: argument --finetune: ignored explicit argument '/home/qichen/.local/share/jupyter/runtime/kernel-v2-17957KT1ZRbrQOgEy.json'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/argparse.py:1800\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1800\u001b[0m     namespace, args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(namespace, _UNRECOGNIZED_ARGS_ATTR):\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/argparse.py:2006\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   2005\u001b[0m     \u001b[38;5;66;03m# consume the next optional and any arguments for it\u001b[39;00m\n\u001b[0;32m-> 2006\u001b[0m     start_index \u001b[38;5;241m=\u001b[39m \u001b[43mconsume_optional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;66;03m# consume any positionals following the last Optional\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/argparse.py:1928\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_optional\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   1927\u001b[0m         msg \u001b[38;5;241m=\u001b[39m _(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignored explicit argument \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1928\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ArgumentError(action, msg \u001b[38;5;241m%\u001b[39m explicit_arg)\n\u001b[1;32m   1930\u001b[0m \u001b[38;5;66;03m# if there is no explicit argument, try to match the\u001b[39;00m\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;66;03m# optional's string arguments with the following strings\u001b[39;00m\n\u001b[1;32m   1932\u001b[0m \u001b[38;5;66;03m# if successful, exit the loop\u001b[39;00m\n\u001b[1;32m   1933\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument --finetune: ignored explicit argument '/home/qichen/.local/share/jupyter/runtime/kernel-v2-17957KT1ZRbrQOgEy.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[2], line 248\u001b[0m\n\u001b[1;32m    246\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--scale_direction\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m--> 248\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m train(args)\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/argparse.py:1768\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1768\u001b[0m     args, argv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argv:\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/argparse.py:1807\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1806\u001b[0m err \u001b[38;5;241m=\u001b[39m _sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1807\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/argparse.py:2521\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2520\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprog\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m: message}\n\u001b[0;32m-> 2521\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%(prog)s\u001b[39;49;00m\u001b[38;5;124;43m: error: \u001b[39;49m\u001b[38;5;132;43;01m%(message)s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/argparse.py:2508\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_message(message, _sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m-> 2508\u001b[0m \u001b[43m_sys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2095\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2093\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2094\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2095\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2098\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2099\u001b[0m         \u001b[38;5;66;03m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   2100\u001b[0m         \u001b[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   2101\u001b[0m         \u001b[38;5;66;03m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/site-packages/IPython/core/ultratb.py:696\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/site-packages/IPython/core/ultratb.py:559\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    556\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    557\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    558\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 559\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    563\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    567\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/site-packages/IPython/core/ultratb.py:1396\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/site-packages/IPython/core/ultratb.py:1287\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1284\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/site-packages/IPython/core/ultratb.py:1140\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1133\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1138\u001b[0m ):\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1140\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/site-packages/IPython/core/ultratb.py:1030\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1028\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1029\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1033\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1034\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/hdmapnet_py38/lib/python3.8/site-packages/IPython/core/ultratb.py:1098\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import logging\n",
    "from time import time\n",
    "from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from loss import SimpleLoss, DiscriminativeLoss\n",
    "\n",
    "# from data.dataset import semantic_dataset\n",
    "from data.const import NUM_CLASSES\n",
    "from evaluation.iou import get_batch_iou\n",
    "from evaluation.angle_diff import calc_angle_diff\n",
    "from model import get_model\n",
    "from evaluate import onehot_encoding, eval_iou\n",
    "from data.vector_map import *\n",
    "\n",
    "from data.dataset import *\n",
    "\n",
    "\n",
    "def write_log(writer, ious, title, counter):\n",
    "    writer.add_scalar(f'{title}/iou', torch.mean(ious[1:]), counter)\n",
    "\n",
    "    for i, iou in enumerate(ious):\n",
    "        writer.add_scalar(f'{title}/class_{i}/iou', iou, counter)\n",
    "\n",
    "def semantic_dataset(version, dataroot, data_conf, bsz, nworkers):\n",
    "    train_dataset = mbmapdatatest(version='v1.0-trainval', dataroot='/home/qichen/projects/Nuscene-full/', data_conf=data_conf, is_train=True)\n",
    "    val_dataset = mbmapdatatest(version, dataroot, data_conf, is_train=False,)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bsz, shuffle=True, num_workers=nworkers, drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=bsz, shuffle=False, num_workers=nworkers)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def train(args):\n",
    "    if not os.path.exists(args.logdir):\n",
    "        os.mkdir(args.logdir)\n",
    "    logging.basicConfig(filename=os.path.join(args.logdir, \"results.log\"),\n",
    "                        filemode='w',\n",
    "                        format='%(asctime)s: %(message)s',\n",
    "                        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                        level=logging.INFO)\n",
    "    logging.getLogger('shapely.geos').setLevel(logging.CRITICAL)\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "    data_conf = {\n",
    "        'num_channels': NUM_CLASSES + 1,\n",
    "        'image_size': args.image_size,\n",
    "        'xbound': args.xbound,\n",
    "        'ybound': args.ybound,\n",
    "        'zbound': args.zbound,\n",
    "        'dbound': args.dbound,\n",
    "        'thickness': args.thickness,\n",
    "        'angle_class': args.angle_class,\n",
    "    }\n",
    "\n",
    "    train_loader, val_loader = semantic_dataset(args.version, args.dataroot, data_conf, args.bsz, args.nworkers)\n",
    "    model = get_model(args.model, data_conf, args.instance_seg, args.embedding_dim, args.direction_pred, args.angle_class)\n",
    "\n",
    "    if args.finetune:\n",
    "        model.load_state_dict(torch.load(args.modelf), strict=False)\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'bevencode.up' in name or 'bevencode.layer3' in name:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    sched = StepLR(opt, 10, 0.1)\n",
    "    writer = SummaryWriter(logdir=args.logdir)\n",
    "    if torch.cuda.is_available():\n",
    "        loss_fn = SimpleLoss(args.pos_weight).cuda()\n",
    "        embedded_loss_fn = DiscriminativeLoss(args.embedding_dim, args.delta_v, args.delta_d).cuda()\n",
    "    else:\n",
    "        loss_fn = SimpleLoss(args.pos_weight)\n",
    "        embedded_loss_fn = DiscriminativeLoss(args.embedding_dim, args.delta_v, args.delta_d)\n",
    "    direction_loss_fn = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    last_idx = len(train_loader) - 1\n",
    "    best_iou = 0.0\n",
    "\n",
    "    \n",
    "    for epoch in range(args.nepochs):\n",
    "        # for batchi, (imgs, trans, rots, intrins, post_trans, post_rots, lidar_data, lidar_mask, car_trans,\n",
    "        #             yaw_pitch_roll, semantic_gt, instance_gt, direction_gt, sample_token) in enumerate(train_loader):\n",
    "        for batchi, (imgs, trans, rots, intrins, post_trans, post_rots, lidar_data, lidar_mask, car_trans,\n",
    "                     yaw_pitch_roll, semantic_gt, instance_gt, direction_gt, sample_token) in enumerate(train_loader):\n",
    "            # print(enumerate(train_loader))\n",
    "            t0 = time()\n",
    "            opt.zero_grad()\n",
    "            if torch.cuda.is_available():\n",
    "                semantic, embedding, direction = model(imgs.cuda(), trans.cuda(), rots.cuda(), intrins.cuda(),\n",
    "                                                    post_trans.cuda(), post_rots.cuda(), lidar_data.cuda(),\n",
    "                                                    lidar_mask.cuda(), car_trans.cuda(), yaw_pitch_roll.cuda(),sample_token[0])\n",
    "                semantic_gt = semantic_gt.cuda().float()\n",
    "                instance_gt = instance_gt.cuda()\n",
    "            else:\n",
    "                semantic, embedding, direction = model(imgs, trans, rots, intrins,\n",
    "                                                    post_trans, post_rots, lidar_data,\n",
    "                                                    lidar_mask, car_trans, yaw_pitch_roll,sample_token[0])\n",
    "                semantic_gt = semantic_gt.float()\n",
    "            seg_loss = loss_fn(semantic, semantic_gt)\n",
    "            # print(semantic_gt.shape)\n",
    "            if args.instance_seg:\n",
    "                var_loss, dist_loss, reg_loss = embedded_loss_fn(embedding, instance_gt)\n",
    "            else:\n",
    "                var_loss = 0\n",
    "                dist_loss = 0\n",
    "                reg_loss = 0\n",
    "\n",
    "            if args.direction_pred:\n",
    "                if torch.cuda.is_available():\n",
    "                    direction_gt = direction_gt.cuda()\n",
    "                lane_mask = (1 - direction_gt[:, 0]).unsqueeze(1)\n",
    "                direction_loss = direction_loss_fn(torch.softmax(direction, 1), direction_gt)\n",
    "                direction_loss = (direction_loss * lane_mask).sum() / (lane_mask.sum() * direction_loss.shape[1] + 1e-6)\n",
    "                angle_diff = calc_angle_diff(direction, direction_gt, args.angle_class)\n",
    "            else:\n",
    "                direction_loss = 0\n",
    "                angle_diff = 0\n",
    "\n",
    "            final_loss = seg_loss * args.scale_seg + var_loss * args.scale_var + dist_loss * args.scale_dist + direction_loss * args.scale_direction\n",
    "            final_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "            opt.step()\n",
    "            counter += 1\n",
    "            t1 = time()\n",
    "            \n",
    "            if counter % 10 == 0:\n",
    "                intersects, union = get_batch_iou(onehot_encoding(semantic), semantic_gt)\n",
    "                iou = intersects / (union + 1e-7)\n",
    "                logger.info(f\"TRAIN[{epoch:>3d}]: [{batchi:>4d}/{last_idx}]    \"\n",
    "                            f\"Time: {t1-t0:>7.4f}    \"\n",
    "                            f\"Loss: {final_loss.item():>7.4f}    \"\n",
    "                            f\"IOU: {np.array2string(iou[1:].numpy(), precision=3, floatmode='fixed')}\")\n",
    "\n",
    "                write_log(writer, iou, 'train', counter)\n",
    "                writer.add_scalar('train/step_time', t1 - t0, counter)\n",
    "                writer.add_scalar('train/seg_loss', seg_loss, counter)\n",
    "                writer.add_scalar('train/var_loss', var_loss, counter)\n",
    "                writer.add_scalar('train/dist_loss', dist_loss, counter)\n",
    "                writer.add_scalar('train/reg_loss', reg_loss, counter)\n",
    "                writer.add_scalar('train/direction_loss', direction_loss, counter)\n",
    "                writer.add_scalar('train/final_loss', final_loss, counter)\n",
    "                writer.add_scalar('train/angle_diff', angle_diff, counter)\n",
    "        \n",
    "        #Anyway to marrallel the loss and eval ???\n",
    "        iou = eval_iou(model, val_loader)\n",
    "        logger.info(f\"EVAL[{epoch:>2d}]:    \"\n",
    "                    f\"IOU: {np.array2string(iou[1:].numpy(), precision=3, floatmode='fixed')}\")\n",
    "\n",
    "        write_log(writer, iou, 'eval', counter)\n",
    "        # Commit Jul-15, training logic improvement that only the best model sofar 'll be stored, Compute the overall IOU for the three subcategories\n",
    "        overall_iou = (iou[1:][0] + iou[1:][1] + iou[1:][2]) / 3\n",
    "        \n",
    "        # Check if this is the best model so far\n",
    "        if overall_iou > best_iou:\n",
    "            best_model = model.state_dict()  # Save the model state\n",
    "            best_iou = overall_iou\n",
    "            best_epoch = epoch  # Save the epoch number\n",
    "            write_log(writer, iou, 'eval', counter)\n",
    "            model_name = os.path.join(args.logdir, f\"model{epoch}.pt\")\n",
    "            torch.save(best_model, model_name)\n",
    "            logger.info(f\"{model_name} saved\")\n",
    "            # Print the current epoch and IOU value\n",
    "            logger.info(f'The new best Epoch found !!! epoch num is : {epoch}, val iou: {iou[1:][0] + iou[1:][1] + iou[1:][2]} , overall IOU: {overall_iou:.4f}')\n",
    "            print(f'The new best Epoch found !!! epoch num is : {epoch}, val iou: {iou[1:][0] + iou[1:][1] + iou[1:][2]} , overall IOU: {overall_iou:.4f}')\n",
    "            \n",
    "        model.train()\n",
    "\n",
    "        sched.step()\n",
    "\n",
    "\n",
    "class mbmapdatatest(HDMapNetSemanticDataset):\n",
    "    def __init__(self, version, dataroot, data_conf, is_train):\n",
    "        super(mbmapdatatest, self).__init__(version, dataroot, data_conf, is_train)\n",
    "        self.vector_map = mbmap(dataroot, patch_size=self.patch_size, canvas_size=self.canvas_size)\n",
    "\n",
    "class mbmap(VectorizedLocalMap):\n",
    "    def __init__(self):\n",
    "        super(mbmap, self).__init__(self,\n",
    "                 dataroot,\n",
    "                 patch_size,\n",
    "                 canvas_size,\n",
    "                 line_classes=['road_divider', 'lane_divider'],\n",
    "                 ped_crossing_classes=['ped_crossing'],\n",
    "                 contour_classes=['road_segment', 'lane'],\n",
    "                 sample_dist=1,\n",
    "                 num_samples=250,\n",
    "                 padding=False,\n",
    "                 normalize=False,\n",
    "                 fixed_num=-1)\n",
    "        '''\n",
    "        Args:\n",
    "            fixed_num = -1 : no fixed num\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.MAPS = ['boston-seaport', 'singapore-hollandvillage',\n",
    "                     'singapore-onenorth', 'singapore-queenstown', 'singapore-hollandvillage-mbfake']\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='HDMapNet training.')\n",
    "    # logging config\n",
    "    parser.add_argument(\"--logdir\", type=str, default='./runs')\n",
    "\n",
    "    # nuScenes config\n",
    "    parser.add_argument('--dataroot', type=str, default='dataset/nuScenes/')\n",
    "    parser.add_argument('--version', type=str, default='v1.0-mini', choices=['v1.0-trainval', 'v1.0-mini'])\n",
    "\n",
    "    # model config\n",
    "    parser.add_argument(\"--model\", type=str, default='HDMapNet_cam')\n",
    "\n",
    "    # training config\n",
    "    parser.add_argument(\"--nepochs\", type=int, default=50)\n",
    "    parser.add_argument(\"--max_grad_norm\", type=float, default=5.0)\n",
    "    parser.add_argument(\"--pos_weight\", type=float, default=2.13)\n",
    "    parser.add_argument(\"--bsz\", type=int, default=4)\n",
    "    parser.add_argument(\"--nworkers\", type=int, default=10)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=1e-7)\n",
    "\n",
    "    # finetune config\n",
    "    parser.add_argument('--finetune', action='store_true')\n",
    "    parser.add_argument('--modelf', type=str, default=None)\n",
    "\n",
    "    # data config\n",
    "    parser.add_argument(\"--thickness\", type=int, default=5)\n",
    "    parser.add_argument(\"--image_size\", nargs=2, type=int, default=[128, 352])\n",
    "    parser.add_argument(\"--xbound\", nargs=3, type=float, default=[-30.0, 30.0, 0.15])\n",
    "    parser.add_argument(\"--ybound\", nargs=3, type=float, default=[-15.0, 15.0, 0.15])\n",
    "    parser.add_argument(\"--zbound\", nargs=3, type=float, default=[-10.0, 10.0, 20.0])\n",
    "    parser.add_argument(\"--dbound\", nargs=3, type=float, default=[4.0, 45.0, 1.0])\n",
    "\n",
    "    # embedding config\n",
    "    parser.add_argument('--instance_seg', action='store_true')\n",
    "    parser.add_argument(\"--embedding_dim\", type=int, default=16)\n",
    "    parser.add_argument(\"--delta_v\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--delta_d\", type=float, default=3.0)\n",
    "\n",
    "    # direction config\n",
    "    parser.add_argument('--direction_pred', action='store_true')\n",
    "    parser.add_argument('--angle_class', type=int, default=36)\n",
    "\n",
    "    # loss config\n",
    "    parser.add_argument(\"--scale_seg\", type=float, default=1.0)\n",
    "    parser.add_argument(\"--scale_var\", type=float, default=1.0)\n",
    "    parser.add_argument(\"--scale_dist\", type=float, default=1.0)\n",
    "    parser.add_argument(\"--scale_direction\", type=float, default=0.2)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    train(args)\n",
    "    \n",
    "    \"\"\"train.py --dataroot /home/qichen/projects/Nuscene-full/ --instance_seg --direction_pred --version v1.0-trainval \n",
    "    --model lift_splat --logdir ./log --xbound -50.0 50.0 0.5 --ybound -50.0 50.0 0.5 \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdmapnet_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
